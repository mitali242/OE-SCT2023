{"cells":[{"cell_type":"markdown","metadata":{"id":"Jxn4V51Pdq5_"},"source":["Prac 1:Write a program to implement various activation function (Identity, Linear, Binary Step, Bipolar Step,Bell Shaped)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1681267327490,"user":{"displayName":"mitali Kotecha","userId":"16323884850002062113"},"user_tz":540},"id":"lQ7h1mZzS5mk","outputId":"2bbcbfca-e080-4dbe-b1a2-ae5dc2da9e29"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","0\n","[1. 2. 3.]\n","[1. 2. 3.]\n","1\n","-1\n","[0.60653066 0.36787944 0.22313016]\n"]}],"source":["import numpy as np\n","\n","def binary_step(x):\n","    if x<0:\n","      return 0\n","    else:\n","      return 1\n","print(binary_step(5)) \n","print(binary_step(-1))\n","\n","def identity_activation(x):\n","    return x\n","input_vec = np.array([1.0, 2.0, 3.0])\n","output_vec = identity_activation(input_vec)\n","print(output_vec)\n","\n","def linear_activation(x):\n","    return x\n","input_vec = np.array([1.0, 2.0, 3.0])\n","output_vec = linear_activation(input_vec)\n","print(output_vec)\n","\n","def bipolar_Step(x):\n","    if x>=0:\n","      return 1\n","    else:\n","      return -1\n","print(bipolar_Step(3))\n","print(bipolar_Step(-2))\n","\n","def gaussian_activation(x, a=1, c=0, w=1):\n","    return a * np.exp(-(x-c)*2 / (2*w*2))\n","input_vec = np.array([1.0, 2.0, 3.0])\n","output_vec = gaussian_activation(input_vec)\n","print(output_vec)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MlcL5zCvV-R1"},"source":["SC prac2:Write suitable programs for implementing logic functions (AND, OR, NOT) using McCulloch-Pitts neuron.(Consider input and output binary data)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1681268082054,"user":{"displayName":"mitali Kotecha","userId":"16323884850002062113"},"user_tz":540},"id":"DZzd1uxCWA88","outputId":"4ed2f02a-947a-45ec-f82c-5950fbf961d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output of AND Function\n","0\n","0\n","0\n","1\n","Output of OR Function\n","0\n","1\n","1\n","1\n","Output of NOT Function\n","1\n","0\n"]}],"source":["def mp_and(x1, x2):\n","    weight1, weight2, theta = 1, 1, 2\n","    y_in = x1*weight1 + x2*weight2\n","    if y_in >= theta:\n","        return 1\n","    else:\n","        return 0\n","\n","# OR function implementation\n","def mp_or(x1, x2):\n","    weight1, weight2, theta = 1, 1, 1\n","    y_in = x1*weight1 + x2*weight2\n","    if y_in >= theta:\n","        return 1\n","    else:\n","        return 0\n","\n","# NOT function implementation\n","def mp_not(x1):\n","    weight1, theta = -1, 0\n","    y_in = x1*weight1\n","    if y_in >= theta:\n","        return 1\n","    else:\n","        return 0\n","\n","print(\"Output of AND Function\")\n","print(mp_and(0, 0))\n","print(mp_and(0, 1))\n","print(mp_and(1, 0))\n","print(mp_and(1, 1))\n","\n","print(\"Output of OR Function\")\n","print(mp_or(0, 0)) # Expected output: 0\n","print(mp_or(0, 1)) # Expected output: 1\n","print(mp_or(1, 0)) # Expected output: 1\n","print(mp_or(1, 1)) # Expected output: 1\n","\n","print(\"Output of NOT Function\")\n","print(mp_not(0)) # Expected output: 1\n","print(mp_not(1)) # Expected output: 0"]},{"cell_type":"markdown","metadata":{"id":"YU5mY8CcY9Rq"},"source":["SC prac3:Write a program to classify the letters using Hebb learning rule."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1681268570646,"user":{"displayName":"mitali Kotecha","userId":"16323884850002062113"},"user_tz":540},"id":"BUGhQoeRY_br","outputId":"8f6af9fa-4e62-419f-a870-d3747a13c93d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input pattern not recognized\n"]}],"source":["import numpy as np\n","\n","# Define the input patterns for each letter\n","letter_A = np.array([[1,1,1,1,1],\n","                     [1,0,0,0,1],\n","                     [1,1,1,1,1],\n","                     [1,0,0,0,1],\n","                     [1,0,0,0,1]])\n","\n","letter_B = np.array([[1,1,1,1,0],\n","                     [1,0,0,0,1],\n","                     [1,1,1,1,0],\n","                     [1,0,0,0,1],\n","                     [1,1,1,1,0]])\n","\n","letter_C = np.array([[0,1,1,1,0],\n","                     [1,0,0,0,1],\n","                     [1,0,0,0,0],\n","                     [1,0,0,0,1],\n","                     [0,1,1,1,0]])\n","\n","# Concatenate the input patterns into a single array\n","input_patterns = np.array([letter_A.flatten(), letter_B.flatten(), letter_C.flatten()])\n","\n","# Initialize the weight matrix using the Hebb rule\n","weights = np.zeros((25,25))\n","for i in range(25):\n","    for j in range(25):\n","        if i == j:\n","            weights[i,j] = 0\n","        else:\n","            for pattern in input_patterns:\n","                weights[i,j] += pattern[i] * pattern[j]\n","            weights[i,j] /= len(input_patterns)\n","\n","# Define the activation function (simple threshold function)\n","def activation(x):\n","    return 1 if x > 0 else 0\n","\n","# Define a function to classify new input patterns using the trained weights\n","def classify(input_pattern, weights):\n","    y = np.zeros(25)\n","    for i in range(25):\n","        y[i] = np.dot(weights[i,:], input_pattern)\n","    output = np.array([activation(y_i) for y_i in y])\n","    return output\n","\n","# Test the classification on a new input pattern\n","letter_D = np.array([[1,1,1,1,0],\n","                     [1,0,0,0,1],\n","                     [1,0,0,0,1],\n","                     [1,0,0,0,1],\n","                     [1,1,1,1,0]])\n","                     \n","output_D = classify(letter_D.flatten(), weights)\n","if np.array_equal(output_D, letter_B.flatten()):\n","    print(\"Input pattern classified as letter B\")\n","else:\n","    print(\"Input pattern not recognized\")"]},{"cell_type":"markdown","metadata":{"id":"YLVwYIoocfDr"},"source":["SC prac4:Write a program to implement single layer perceptron network."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"elapsed":21330,"status":"ok","timestamp":1681270287167,"user":{"displayName":"mitali Kotecha","userId":"16323884850002062113"},"user_tz":540},"id":"ojFsm2Q6chd7","outputId":"28f3b016-dcbd-4212-9a0f-6a65c82151f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4648 - accuracy: 0.8788\n","Epoch 2/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.9151\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2834 - accuracy: 0.9204\n","Epoch 4/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2730 - accuracy: 0.9236\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2669 - accuracy: 0.9255\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.9259\n"]},{"data":{"text/plain":["[0.2662440538406372, 0.9258999824523926]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 480x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n","len(x_train)\n","len(x_test)\n","x_train[0].shape\n","plt.matshow(x_train[0])\n","\n","# Normalizing the dataset\n","x_train = x_train/255\n","x_test = x_test/255\n","  \n","# Flatting the dataset in order\n","# to compute for model building\n","x_train_flatten = x_train.reshape(len(x_train), 28*28)\n","x_test_flatten = x_test.reshape(len(x_test), 28*28)\n","\n","model = keras.Sequential([keras.layers.Dense(10, input_shape=(784,),activation='sigmoid')])\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy'])\n","  \n","model.fit(x_train_flatten, y_train, epochs=5)\n","\n","model.evaluate(x_test_flatten, y_test)\n"]},{"cell_type":"markdown","metadata":{"id":"TD2eZ4lFi8yq"},"source":["SC Prac5:Write suitable programs for implementing Adaline network. (assume suitable input)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1681270717666,"user":{"displayName":"mitali Kotecha","userId":"16323884850002062113"},"user_tz":540},"id":"yjoDs8EKiwTb","outputId":"521fb842-11ec-4f72-e058-1c8d6003815e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-1 -1]\n"," [-1  1]\n"," [ 1 -1]\n"," [ 1  1]] [-1  1  1  1]\n","epoch : 1\n","error = -0.09999999999999998\n","error = 0.9199999999999999\n","error = 1.1039999999999999\n","error = -0.5247999999999999\n","sum of squared error =  0.5876577599999998 \n","\n","\n","epoch : 2\n","error = -0.54976\n","error = 0.803712\n","error = 0.8172543999999999\n","error = -0.64406528\n","sum of squared error =  0.5077284689412096 \n","\n","\n","epoch : 3\n","error = -0.6729103360000002\n","error = 0.7483308032\n","error = 0.7399630438400001\n","error = -0.6898669486079996\n","sum of squared error =  0.5090672560860652 \n","\n","\n","epoch : 4\n","error = -0.7047962935296\n","error = 0.72625757847552\n","error = 0.7201693816586239\n","error = -0.7061914301759491\n","sum of squared error =  0.5103845399996764 \n","\n","\n","epoch : 5\n","error = -0.7124421954738586\n","error = 0.7182636328518943\n","error = 0.7154472043637898\n","error = -0.7117071786082882\n","sum of squared error =  0.5104670846209363 \n","\n","\n"]}],"source":["# import the module numpy\n","import numpy as np\n"," \n"," \n","# the features for the or model , here we have\n","# taken the possible values for combination of\n","# two inputs\n","features = np.array(\n","    [\n","        [-1, -1],\n","        [-1, 1],\n","        [1, -1],\n","        [1, 1]\n","    ])\n"," \n"," \n","# labels for the or model, here the output for\n","# the features is taken as an array\n","labels = np.array([-1, 1, 1, 1])\n"," \n","# to print the features and the labels for\n","# which the model has to be trained\n","print(features, labels)\n"," \n","# initialise weights, bias , learning rate, epoch\n","weight = [0.5, 0.5]\n","bias = 0.1\n","learning_rate = 0.2\n","epoch = 5\n"," \n","for i in range(epoch):\n","   \n","    # epoch is the number of the model is trained\n","    # with the same data\n","    print(\"epoch :\", i+1)\n"," \n","    # variable to check if there is no change in previous\n","    # weight and present calculated weight\n","    # initial error is kept as 0\n","    sum_squared_error = 0.0\n"," \n","    # for each of the possible input given in the features\n","    for j in range(features.shape[0]):\n"," \n","        # actual output to be obtained\n","        actual = labels[j]\n"," \n","        # the value of two features as given in the features\n","        # array\n","        x1 = features[j][0]\n","        x2 = features[j][1]\n"," \n","        # net unit value computation performed to obtain the\n","        # sum of features multiplied with their weights\n","        unit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n"," \n","        # error is computed so as to update the weights\n","        error = actual - unit\n"," \n","        # print statement to print the actual value , predicted\n","        # value and the error\n","        print(\"error =\", error)\n"," \n","        # summation of squared error is calculated\n","        sum_squared_error += error * error\n"," \n","        # updation of weights, summing up of product of learning rate ,\n","        # sum of squared error and feature value\n","        weight[0] += learning_rate * error * x1\n","        weight[1] += learning_rate * error * x2\n"," \n","        # updation of bias, summing up of product of learning rate and\n","        # sum of squared error\n","        bias += learning_rate * error\n"," \n","    print(\"sum of squared error = \", sum_squared_error/4, \"\\n\\n\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPCP0klmKjIS9kKqS5uRRsh","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
